# -*- coding: utf-8 -*-
"""Copy of project on kidney disese

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mBYs_kwl5Qqfb6q6q5vZkJvmrM0JNzG3

Install & Importing the Dependencies
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

import warnings
warnings.filterwarnings('ignore')

"""Extract the Data-Set ( Kidney_Disease.csv )"""

kidney=pd.read_csv('kidney_disease.csv')

kidney.shape

"""It Indicates there are about 400 Rows and 26 Columns are present in our Data Set"""

kidney.head()

kidney.info()

kidney.describe()

"""Performing Exploitory Data Analysis ( EDA )

Modifying the Column Names as per our requirements
"""

columns=pd.read_csv('/content/kidney_disease.csv')
columns=columns.reset_index()

# Renaming specific columns
kidney = kidney.rename(columns={'old_col1': 'cols', 'old_col2': 'abb_col_names'})

# Verify the changes
print(kidney.head())

columns

kidney.head()

# Check the columns of the 'columns' DataFrame
print(columns.columns)

# If 'abb_col_names' exists, proceed; otherwise, adjust according to actual column names

kidney.describe().T

def convert_dtype(kidney,feature):
    kidney[feature]=pd.to_numeric(kidney[feature],errors='coerce')    #whereever we have Nan values , this errors parameter will hanfle that

kidney.dtypes

kidney.drop('id',inplace=True,axis=1)

"""Performing Data cleaning"""

def extract_cat_num(kidney):
    cat_col=[col for col in kidney.columns if kidney[col].dtype=='O']
    num_col=[col for col in kidney.columns if kidney[col].dtype!='O']
    return cat_col,num_col

cat_col,num_col=extract_cat_num(kidney)

cat_col

num_col

# dirtiness in categorical data
for col in cat_col:
    print('{} has {} values'.format(col,kidney[col].unique()))
    print("\n")

# Print all the column names in the kidney DataFrame to find the correct name
print(kidney.columns)

# no dirtiness
for col in cat_col:
    print('{} has {} values'.format(col,kidney[col].unique()))
    print("\n")

"""Analysing distribution of each and every column"""

len(num_col)

plt.figure(figsize=(30,30))
for i,feature in enumerate(num_col):
    plt.subplot(5,3,i+1)   # 5 rows and 3 columns
    kidney[feature].hist()
    plt.title(feature)

"""check Label distribution of categorical Data



"""

len(cat_col)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset (adjust the path if needed)
kidney = pd.read_csv('/content/kidney_disease.csv')

# Clean the column names by stripping spaces
kidney.columns = kidney.columns.str.strip().str.lower()

# Define categorical columns (this is an example; adjust based on your actual DataFrame)
cat_col = [
    'diabetes mellitus',
    'coronary artery disease',
    'class',
    # Add other categorical columns here
]

# Create count plots for categorical features
plt.figure(figsize=(20, 20))

for i, feature in enumerate(cat_col):
    plt.subplot(4, 3, i + 1)  # Create a 4x3 grid of subplots

    plt.title(f'Countplot of {feature}')  # Add titles for clarity

plt.tight_layout()  # Adjust layout to prevent overlap
plt.show()

plt.figure(figsize=(20,20))

for i,feature in enumerate(cat_col):
    plt.subplot(4,3,i+1)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset (adjust the path if needed)
kidney = pd.read_csv('/content/kidney_disease.csv')

# Clean the column names by stripping spaces and converting to lower case
kidney.columns = kidney.columns.str.strip().str.lower()

# Print the columns to ensure 'classification' exists
print(kidney.columns)  # Check the available columns in the DataFrame

# Create a count plot for the 'classification' column
plt.figure(figsize=(10, 6))  # Set the figure size
sns.countplot(data=kidney, x='classification')  # Use the correct column name
plt.title('Countplot of Classification')  # Add a title
plt.xlabel('Classification')  # Label x-axis
plt.ylabel('Count')  # Label y-axis
plt.show()  # Display the plot

"""Correlation between features"""

import pandas as pd

# Load the dataset (adjust the path if needed)
kidney = pd.read_csv('/content/kidney_disease.csv')

# Clean the column names by stripping spaces and converting to lower case
kidney.columns = kidney.columns.str.strip().str.lower()

# Check the data types of each column
print(kidney.dtypes)  # Print the data types of the columns

# Select only numeric columns for correlation
numeric_cols = kidney.select_dtypes(include=['number']).columns

# Compute the correlation matrix
correlation_matrix = kidney[numeric_cols].corr()

# Print the correlation matrix
print(correlation_matrix)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset (adjust the path if needed)
kidney = pd.read_csv('/content/kidney_disease.csv')

# Clean the column names by stripping spaces and converting to lower case
kidney.columns = kidney.columns.str.strip().str.lower()

# Check the data types of each column
print(kidney.dtypes)  # Print the data types of the columns

# Select only numeric columns for correlation
numeric_cols = kidney.select_dtypes(include=['number']).columns

# If you want to also check which columns are non-numeric, you can print them:
non_numeric_cols = kidney.select_dtypes(exclude=['number']).columns
print("Non-numeric columns:", non_numeric_cols)

# Compute the correlation matrix using only numeric columns
correlation_matrix = kidney[numeric_cols].corr(method='pearson')

# Create a heatmap of the correlation matrix
plt.figure(figsize=(12, 12))
sns.heatmap(correlation_matrix, cbar=True, cmap='BuPu', annot=True, fmt='.2f')

# Set the title
plt.title('Correlation Heatmap of Kidney Dataset')
plt.show()  # Display the plot

"""1.Rbc count is positively correlated with specific gravity,haemoglobin,packed cell volume
2.Rbc count is negatively correlated with albumin, blood urea
3.Packed cell volume and haemoglobin are highly positive correlated
4.Packed cell volume is negatively correlated with albumin and blood urea
5.haemoglobin and albumin are negatively correlated
"""

import pandas as pd

# Load the dataset (adjust the path if needed)
kidney = pd.read_csv('/content/kidney_disease.csv')

# Clean the column names by stripping spaces and converting to lower case
kidney.columns = kidney.columns.str.strip().str.lower()

# Check the data types of the relevant columns
print(kidney[['rbc', 'rc', 'classification']].dtypes)  # Print data types for relevant columns

# Convert 'rc' to numeric, forcing non-numeric values to NaN
kidney['rc'] = pd.to_numeric(kidney['rc'], errors='coerce')

# Check for any NaN values in 'rc' after conversion
print(kidney['rc'].isna().sum(), "NaN values in 'rc' after conversion.")

# Now perform the groupby operation
try:
    result = kidney.groupby(['rbc', 'classification'])['rc'].agg(['count', 'mean', 'median', 'min', 'max'])
    print(result)
except KeyError as e:
    print(f"KeyError: {e}")
except TypeError as e:
    print(f"TypeError: {e}")

"""Relationship between haemoglobin and packed cell volume"""

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset (adjust the path if needed)
kidney = pd.read_csv('/content/kidney_disease.csv')

# Clean the column names by stripping spaces and converting to lower case
kidney.columns = kidney.columns.str.strip().str.lower()

# Check data types of relevant columns
print(kidney[['hemo', 'pcv']].dtypes)

# Convert 'hemo' and 'pcv' to numeric, coercing errors to NaN
kidney['hemo'] = pd.to_numeric(kidney['hemo'], errors='coerce')
kidney['pcv'] = pd.to_numeric(kidney['pcv'], errors='coerce')

# Check for NaN values in 'hemo' and 'pcv'
print(f"NaN values in 'hemo': {kidney['hemo'].isna().sum()}")
print(f"NaN values in 'pcv': {kidney['pcv'].isna().sum()}")

# Drop rows with NaN values in 'hemo' or 'pcv'
kidney_cleaned = kidney.dropna(subset=['hemo', 'pcv'])

# Create scatter plot
plt.figure(figsize=(10, 10))
plt.scatter(x=kidney_cleaned['hemo'], y=kidney_cleaned['pcv'])
plt.xlabel('Haemoglobin')
plt.ylabel('Packed Cell Volume')
plt.title('Relationship between Haemoglobin and Packed Cell Volume')
plt.grid(True)  # Add grid for better visualization
plt.show()  # Display the plot

"""We can see that there is a linear relationship between haemoglobin and pacled cell volume

Analyse distribution of red blood cell count chronic as well as non chronic
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset (adjust the path if needed)
kidney = pd.read_csv('/content/kidney_disease.csv')

# Clean the column names by stripping spaces and converting to lower case
kidney.columns = kidney.columns.str.strip().str.lower()

# Convert 'rc' to numeric, forcing non-convertible values to NaN
kidney['rc'] = pd.to_numeric(kidney['rc'], errors='coerce')

# Check for NaN values in 'rc' and drop them if needed
kidney.dropna(subset=['rc'], inplace=True)

# Create a FacetGrid for KDE plot
grid = sns.FacetGrid(kidney, hue='classification', aspect=2)  # Use 'classification' for hue
grid.map(sns.kdeplot, 'rc')  # Use 'rc' for 'red blood cell count'
grid.add_legend()

# Show the plot
plt.title('KDE Plot of Red Blood Cell Count by Class')
plt.xlabel('Red Blood Cell Count')
plt.ylabel('Density')
plt.show()  # Display the plot

"""from above visuals we can say that person with lower rbc count have high chances of having chronic disease"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset (adjust the path if needed)
kidney = pd.read_csv('/content/kidney_disease.csv')

# Clean the column names by stripping spaces and converting to lower case
kidney.columns = kidney.columns.str.strip().str.lower()

# Convert 'rc' to numeric, forcing non-convertible values to NaN
kidney['rc'] = pd.to_numeric(kidney['rc'], errors='coerce')

# Check for NaN values in 'rc' and drop them if needed
kidney.dropna(subset=['rc'], inplace=True)

# Change 'class' to 'classification' for hue parameter
grid = sns.FacetGrid(kidney, hue='classification', aspect=2)  # Use 'classification' for hue instead of 'class'
# Replace 'haemoglobin' with the correct column name, for instance 'hgb'
# Print the available columns to find the correct name for haemoglobin
print(kidney.columns)
# Based on the printed columns, use the correct column name below:
# If the column name is 'hemo', use 'hemo' instead of 'hgb'
grid.map(sns.kdeplot, 'hemo')  # Assuming 'hemo' is the correct column name for haemoglobin after cleaning column names
grid.add_legend()

plt.title('KDE Plot of Red Blood Cell Count by Class')
plt.xlabel('Red Blood Cell Count')
plt.ylabel('Density')
plt.show()  # Display the plot

plt.figure(figsize=(12,10))
sns.scatterplot(x=kidney['rbc'], y=kidney['pcv'], hue=kidney['classification'])  # Changed column names to lowercase
plt.xlabel('red blood cell count')
plt.ylabel('packed cell volume')
plt.title('Relationship between red blood cell count and packed cell volume')

import matplotlib.pyplot as plt  # Import the necessary module
import seaborn as sns
import pandas as pd

# ... (Rest of your code) ...

plt.figure(figsize=(12, 10))
# ... (Rest of your plotting code) ...

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset (adjust the path if needed)
kidney = pd.read_csv('/content/kidney_disease.csv')

# Clean the column names by stripping spaces and converting to lower case
kidney.columns = kidney.columns.str.strip().str.lower()

# ... (Rest of the data cleaning code) ...

plt.figure(figsize=(12, 10))
# Use the cleaned column names 'rbc', 'hemo' (or 'hgb'), and 'classification'
sns.scatterplot(x=kidney['rbc'], y=kidney['hemo'], hue=kidney['classification'])
plt.xlabel('red blood cell count')
plt.ylabel('haemoglobin')
plt.title('Relationship between haemoglobin and red blood cell count')
plt.show()

kidney.isnull().sum()

kidney.isnull().sum().sort_values(ascending=False)

plt.subplot(1,2,1)
sns.boxplot(x=kidney['classification'],y=kidney['age'])  # Replace 'class' with 'classification'

cat_col = kidney.select_dtypes(include=['object']).columns.tolist()

# Now you can use cat_col
list(enumerate(cat_col))

import seaborn as sns
import matplotlib.pyplot as plt

# Define num_col to store the numerical column names
num_col = kidney.select_dtypes(include=['number']).columns.tolist()

plt.figure(figsize=(15,15))
for i in enumerate(num_col):
    plt.subplot(4,4,i[0]+1)
    sns.boxplot(x=kidney['classification'],y=i[1],data=kidney.reset_index()) # Replace 'class' with 'classification'

import numpy as np # Import the numpy library and alias it as 'np'

# Calculate the mean of only numerical columns
numerical_kidney = kidney.select_dtypes(include=np.number)
np.mean(numerical_kidney)

kidney.isnull().sum()

for i in num_col:
    kidney[i].fillna(kidney[i].median(),inplace=True)

kidney.isnull().sum()

kidney.describe()

print(kidney.columns)

kidney['rbc'].isnull().sum() # Replace 'rbc' with the actual column name

# Print the columns in the kidney dataframe to identify the correct name
print(kidney.columns)

# Replace 'red blood cells' with the actual column name, for example 'rbc' or 'red_blood_cells'
random_sample = kidney['rbc'].dropna().sample(152) # Replace 'rbc' with the correct column name

random_sample

print(kidney.columns)

# Print the columns to find the correct one
print(kidney.columns)

# Assuming the correct column name is 'rbc' from the printed list
null_rbc_indices = kidney[kidney['rbc'].isnull()].index
print(null_rbc_indices)

random_sample.index

# Assuming 'rbc' represents 'red blood cells' based on the previous code snippets
random_sample.index = kidney[kidney['rbc'].isnull()].index

random_sample.index

# Replace 'red blood cells' with the correct column name, likely 'rbc'
kidney.loc[kidney['rbc'].isnull(), 'rbc'] = random_sample

kidney.head()

# Replace 'red blood cells' with the correct column name, likely 'rbc'
kidney['rbc'].isnull().sum()

# Print the columns to find the correct one
print(kidney.columns)

# Assuming the correct column name is 'rbc' from the printed list
null_rbc_indices = kidney[kidney['rbc'].isnull()].index
print(null_rbc_indices)

import seaborn as sns
import pandas as pd # Assuming you are using pandas

# Print the columns to confirm the correct column name
print(kidney.columns)

# Assuming the correct column name is 'rbc' or similar based on the output
sns.countplot(x='rbc', data=kidney)  # Change 'rbc' to the actual column name

#filling random values in all categorical columns
def Random_value_Imputation(feature):
    random_sample=kidney[feature].dropna().sample(kidney[feature].isnull().sum())
    random_sample.index=kidney[kidney[feature].isnull()].index
    kidney.loc[kidney[feature].isnull(),feature]=random_sample

#filling random values in all categorical columns
def Random_value_Imputation(feature):
    # Ensure feature name is correct (e.g., 'pc' instead of ' pus cell')
    # This line assumes the correct column name is 'pc' based on the error message
    # You may need to adjust this to the actual column name in your DataFrame
    feature = 'pc' if feature == ' pus cell' else feature
    random_sample=kidney[feature].dropna().sample(kidney[feature].isnull().sum())
    random_sample.index=kidney[kidney[feature].isnull()].index
    kidney.loc[kidney[feature].isnull(),feature]=random_sample

kidney.isnull().sum()

def impute_mode(feature):
    mode=kidney[feature].mode()[0]
    kidney[feature]=kidney[feature].fillna(mode)

for col in cat_col:
    impute_mode(col)

kidney[cat_col].isnull().sum()

kidney.isnull().sum()

for col in cat_col:
    print('{} has {} categories'.format(col,kidney[col].nunique()))

from sklearn.preprocessing import LabelEncoder

le=LabelEncoder()

for col in cat_col:
    kidney[col]=le.fit_transform(kidney[col])

kidney.head()

from sklearn.feature_selection import SelectKBest

from sklearn.feature_selection import chi2

ind_col=[col for col in kidney.columns if col!='class']
dep_col='class'

ind_col=[col for col in kidney.columns if col!='classification']
dep_col='classification'

X=kidney[ind_col]
y=kidney[dep_col]

X.head()

imp_features=SelectKBest(score_func=chi2,k=20)

imp_features=imp_features.fit(X,y)

imp_features

imp_features.scores_

datascore=pd.DataFrame(imp_features.scores_,columns=['Score'])

datascore

X.columns

dfcols=pd.DataFrame(X.columns)

dfcols

features_rank=pd.concat([dfcols,datascore],axis=1)
features_rank

features_rank.columns=['features','score']

features_rank

features_rank.nlargest(10,'score')

selected=features_rank.nlargest(10,'score')['features'].values

selected

X_new=kidney[selected]

X_new.head()

len(X_new)

X_new.shape

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X_new,y,random_state=0,test_size=0.3)

X_train.shape

y_train.value_counts()

from xgboost import XGBClassifier

params={'learning-rate':[0,0.5,0.20,0.25],
        'max_depth':[5,8,10],
       'min_child_weight':[1,3,5,7],
       'gamma':[0.0,0.1,0.2,0.4],
       'colsample_bytree':[0.3,0.4,0.7]}

from sklearn.model_selection import RandomizedSearchCV

classifier=XGBClassifier()

random_search=RandomizedSearchCV(classifier,param_distributions=params,n_iter=5,scoring='roc_auc',n_jobs=-1,cv=5,verbose=3)

random_search.fit(X_train,y_train)

random_search.best_estimator_

random_search.best_params_

classifier=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
              colsample_bynode=1, colsample_bytree=0.3, gamma=0.2, gpu_id=-1,
              importance_type='gain', interaction_constraints='', learning_rate=0.300000012, max_delta_step=0,
              max_depth=5, min_child_weight=1,
              monotone_constraints='()', n_estimators=100, n_jobs=8,
              num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,
              scale_pos_weight=1, subsample=1, tree_method='exact',
              validate_parameters=1, verbosity=None)

classifier.fit(X_train,y_train)

y_pred=classifier.predict(X_test)

y_pred

from sklearn.metrics import confusion_matrix,accuracy_score

confusion_matrix(y_test,y_pred)

import numpy as np # Import the numpy library and alias it as 'np'

np.array([[70,  2], # Use np.array to create the NumPy array
       [ 0, 48]], dtype=np.int64) # Also use np.int64 for the data type

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.metrics import classification_report, accuracy_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

# Load the dataset
file_path = '/content/kidney_disease.csv'  # Replace with your file path if necessary
data = pd.read_csv(file_path)

# Drop 'id' column as it's not useful for the model
data = data.drop('id', axis=1)

# Impute missing values
imputer = SimpleImputer(strategy='mean')

# Identify numerical and categorical columns
num_cols = data.select_dtypes(include=['float64', 'int64']).columns
cat_cols = data.select_dtypes(include=['object']).columns

# Impute missing values for numerical columns
data[num_cols] = imputer.fit_transform(data[num_cols])

# Fill missing categorical values with the most frequent value
data[cat_cols] = data[cat_cols].fillna(data[cat_cols].mode().iloc[0])

# Encode categorical columns
label_encoder = LabelEncoder()
for col in cat_cols:
    data[col] = label_encoder.fit_transform(data[col])

# Split the dataset into features and target variable
X = data.drop('classification', axis=1)
y = data['classification']

# Normalize the numeric features
scaler = StandardScaler()
X[num_cols] = scaler.fit_transform(X[num_cols])

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Build the Neural Network model
model = Sequential()

# Input layer and first hidden layer
model.add(Dense(units=64, activation='relu', input_shape=(X_train.shape[1],)))

# Add more hidden layers
model.add(Dense(units=32, activation='relu'))
model.add(Dense(units=16, activation='relu'))

# Output layer (binary classification: 'ckd' or 'notckd')
model.add(Dense(units=1, activation='sigmoid'))

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test), verbose=1)

# Make predictions on the test set
y_pred = (model.predict(X_test) > 0.5).astype("int32")

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)

# Output the results
print(f"Accuracy: {accuracy * 100:.2f}%")
print("Classification Report:")
print(classification_rep)

pip install pandas scikit-learn

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score

# Load the dataset
file_path = 'kidney_disease.csv'  # Replace with your file path if necessary
data = pd.read_csv(file_path)

# Drop 'id' column as it's not useful for the model
data = data.drop('id', axis=1)

# Impute missing values
imputer = SimpleImputer(strategy='mean')

# Identify numerical and categorical columns
num_cols = data.select_dtypes(include=['float64', 'int64']).columns
cat_cols = data.select_dtypes(include=['object']).columns

# Impute missing values for numerical columns
data[num_cols] = imputer.fit_transform(data[num_cols])

# Fill missing categorical values with the most frequent value
data[cat_cols] = data[cat_cols].fillna(data[cat_cols].mode().iloc[0])

# Encode categorical columns
label_encoder = LabelEncoder()
for col in cat_cols:
    data[col] = label_encoder.fit_transform(data[col])

# Split the dataset into features and target variable
X = data.drop('classification', axis=1)
y = data['classification']

# Normalize the numeric features
scaler = StandardScaler()
X[num_cols] = scaler.fit_transform(X[num_cols])

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize the Decision Tree Classifier
clf = DecisionTreeClassifier(random_state=42)

# Train the model
clf.fit(X_train, y_train)

# Make predictions on the test set
y_pred = clf.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)

# Output the results
print(f"Accuracy: {accuracy * 100:.2f}%")
print("Classification Report:")
print(classification_rep)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, accuracy_score

# Load the dataset
file_path = '/content/kidney_disease.csv'  # Replace with your file path if necessary
data = pd.read_csv(file_path)

# Drop 'id' column as it's not useful for the model
data = data.drop('id', axis=1)

# Impute missing values
imputer = SimpleImputer(strategy='mean')

# Identify numerical and categorical columns
num_cols = data.select_dtypes(include=['float64', 'int64']).columns
cat_cols = data.select_dtypes(include=['object']).columns

# Impute missing values for numerical columns
data[num_cols] = imputer.fit_transform(data[num_cols])

# Fill missing categorical values with the most frequent value
data[cat_cols] = data[cat_cols].fillna(data[cat_cols].mode().iloc[0])

# Encode categorical columns
label_encoder = LabelEncoder()
for col in cat_cols:
    data[col] = label_encoder.fit_transform(data[col])

# Split the dataset into features and target variable
X = data.drop('classification', axis=1)
y = data['classification']

# Normalize the numeric features
scaler = StandardScaler()
X[num_cols] = scaler.fit_transform(X[num_cols])

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6, random_state=42)

# Initialize the KNN classifier with 5 neighbors
knn = KNeighborsClassifier(n_neighbors=5)

# Train the model
knn.fit(X_train, y_train)

# Make predictions on the test set
y_pred = knn.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)

# Output the results
print(f"Accuracy: {accuracy * 100:.2f}%")
print("Classification Report:")
print(classification_rep)

